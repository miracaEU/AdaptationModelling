{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation of CI - A multi-level approach\n",
    "In this example we demonstrate how adaptations of different levels (hazard-, asset-, network- and system-level) can be appraised based on their cost of adaptation, risk, and benefits of adaptation. This notebook covers the calculation of adaptation benefits and and initial costs.\n",
    "\n",
    "### Adaptation of CI - Calculate adaptations\n",
    "*Level 1 - Hazard level adaptation (build floodwall)*\n",
    "\n",
    "*Level 2 - Asset level adaptation (elevate railway as viaduct)*\n",
    "\n",
    "*Level 3 - Network level adaptation (new bridges between assets)*\n",
    "\n",
    "*Level 4 - System level adaptation (reduce traffic and freight demand)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir('path/to/book/directory')\n",
    "# os.chdir('..')\n",
    "from src.ci_adapt_utilities import *\n",
    "\n",
    "data_path = Path(os.getcwd() + '/data')\n",
    "interim_data_path = data_path / 'interim' / 'collected_flood_runs'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default configuration and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file=Path(os.getcwd() + '/config_ci_adapt_test.ini')\n",
    "hazard_type, infra_type, country_code, country_name, hazard_data_subfolders, asset_data, vulnerability_data = load_config(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load asset data, adaptation cost data, and results from baseline (no adaptation) risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675 assets loaded.\n",
      "Loaded data from baseline impact assessment\n",
      "Creating virtual graph...\n",
      "Success: only int type values\n"
     ]
    }
   ],
   "source": [
    "assets, geom_dict, _, return_period_dict, adaptation_unit_costs, rp_spec_priority, average_road_cost_per_ton_km, average_train_cost_per_ton_km, average_train_load_tons = startup_ci_adapt(data_path, config_file)\n",
    "\n",
    "# Load data from baseline impact assessment\n",
    "shortest_paths = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'shortest_paths.pkl', 'rb'))\n",
    "disrupted_edges_by_basin = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'disrupted_edges_by_basin.pkl', 'rb'))\n",
    "graph_r0 = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'graph_0.pkl', 'rb'))\n",
    "disrupted_shortest_paths = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'disrupted_shortest_paths.pkl', 'rb'))\n",
    "event_impacts = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'event_impacts.pkl', 'rb'))\n",
    "full_flood_event=pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'full_flood_event.pkl', 'rb'))\n",
    "all_disrupted_edges = pickle.load(open(data_path / 'interim' / 'indirect_damages' / 'all_disrupted_edges.pkl', 'rb'))\n",
    "collect_output = pickle.load(open(data_path / 'interim' / 'collected_flood_runs' / 'sample_collected_run.pkl', 'rb'))\n",
    "print('Loaded data from baseline impact assessment')\n",
    "graph_v0=create_virtual_graph(graph_r0)\n",
    "graph_v=graph_v0.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define adaptations to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptations={}\n",
    "adaptations['baseline'] = {'l1_l2_adapt_path': None, 'added_links':[], 'l4_adapt_path': None}\n",
    "adaptations['l1_trib'] = {'l1_l2_adapt_path': data_path/r'input\\adaptations\\l1_tributary.geojson', 'added_links':[], 'l4_adapt_path': None}\n",
    "adaptations['l2_trib'] = {'l1_l2_adapt_path': data_path/r'input\\adaptations\\l2_tributary.geojson', 'added_links':[], 'l4_adapt_path': None}\n",
    "adaptations['l3_trib'] = {'l1_l2_adapt_path': None, 'added_links':[(219651487, 111997047)], 'l4_adapt_path': None}\n",
    "adaptations['l4_trib'] = {'l1_l2_adapt_path': None, 'added_links':[], 'l4_adapt_path': data_path/r'input\\adaptations\\l4_tributary.geojson'}\n",
    "\n",
    "# Other adaptations can be added\n",
    "# adaptations['l1_rhine'] = {'l1_l2_adapt_path': data_path/r'input\\adaptations\\l1_rhine.geojson', 'added_links':[], 'l4_adapt_path': None}\n",
    "# adaptations['l2_rhine'] = {'l1_l2_adapt_path': data_path/r'input\\adaptations\\l2_rhine.geojson', 'added_links':[], 'l4_adapt_path': None}\n",
    "# adaptations['l3_rhine'] = {'l1_l2_adapt_path': None, 'added_links':[(112044105, 110947346)], 'l4_adapt_path': None}\n",
    "# adaptations['l4_rhine'] = {'l1_l2_adapt_path': None, 'added_links':[], 'l4_adapt_path': data_path/r'input\\adaptations\\l4_rhine.geojson'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply adaptations and recalculate risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 scenarios:\n",
      "-  baseline\n",
      "-  l1_trib\n",
      "-  l2_trib\n",
      "-  l3_trib\n",
      "-  l4_trib\n",
      "Applying adaptation:  fwall_nahe\n",
      "Level 1 adaptation\n",
      "Applying adaptation:  elev_nahe\n",
      "Level 2 adaptation\n",
      "Applying adaptation:  elev_nahe\n",
      "Level 2 adaptation\n",
      "Applying adaptation:  elev_nahe\n",
      "Level 2 adaptation\n",
      "Applying adaptation: new connection between assets with osm_id  (219651487, 111997047)\n",
      "Level 3 adaptation\n",
      "Applying adaptation: shifted demand for routes:  [('node_682', 'node_684'), ('node_684', 'node_682'), ('node_260', 'node_387'), ('node_387', 'node_260'), ('node_387', 'node_434'), ('node_387', 'node_286'), ('node_434', 'node_387'), ('node_286', 'node_387')]\n",
      "Level 4 adaptation\n"
     ]
    }
   ],
   "source": [
    "# Store results in dictionaries\n",
    "direct_damages_adapted_dict = {}\n",
    "indirect_damages_adapted_dict = {}\n",
    "indirect_damages_adapted_full_dict = {}\n",
    "adaptation_costs={}\n",
    "adapted_assets_dict = {}\n",
    "\n",
    "# Print adaptations that will be run\n",
    "print(f\"Processing {len(adaptations)} scenarios:\")\n",
    "for adapt_id in adaptations.keys():\n",
    "    print('- ',adapt_id)\n",
    "\n",
    "for adapt_id in adaptations.keys():\n",
    "    adaptations_df_path = data_path / 'interim' / 'adaptations' / f'{adapt_id}_adaptations.csv'\n",
    "\n",
    "    if adaptations_df_path.exists():\n",
    "        print(f\"Adaptation {adapt_id} already processed. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Reset graph\n",
    "    graph_v=graph_v0.copy()\n",
    "\n",
    "    # Load adaptations dictionary to the relevant variables\n",
    "    l1_l2_adapt_path = adaptations[adapt_id]['l1_l2_adapt_path']\n",
    "    added_links = adaptations[adapt_id]['added_links']  \n",
    "    l4_adapt_path = adaptations[adapt_id]['l4_adapt_path']\n",
    "\n",
    "    # Load adaptation data\n",
    "    if l1_l2_adapt_path is not None:\n",
    "        adapted_area = gpd.read_file(l1_l2_adapt_path).to_crs(3857)\n",
    "    else:\n",
    "        adapted_area = None\n",
    "    if l4_adapt_path is not None:\n",
    "        adapted_route_area = gpd.read_file(l4_adapt_path).to_crs(3857)\n",
    "    else:\n",
    "        adapted_route_area = None\n",
    "\n",
    "    # Apply adaptations\n",
    "    adapted_assets, adaptations_df, demand_reduction_dict, l3_adaptation_costs = apply_adaptations(adapted_area, assets, collect_output, interim_data_path, rp_spec_priority, adaptation_unit_costs, shortest_paths, graph_v, added_links, adapted_route_area)\n",
    "\n",
    "    # Calculate l1 adaptation costs\n",
    "    local_haz_path=Path(data_path / 'Floods/Germany/basin_intersections')\n",
    "    l1_adaptation_costs=calculate_l1_costs(local_haz_path, interim_data_path, adapted_area, adaptation_unit_costs, adapted_assets) \n",
    "\n",
    "    # Run adapted damages for individual hazard maps\n",
    "    direct_damages_adapted, indirect_damages_adapted, adaptation_run_full, l2_adaptation_costs, overlay_assets_lists = run_adapted_damages(data_path, config_file, collect_output, disrupted_edges_by_basin, interim_data_path, assets, geom_dict, adapted_assets, adaptations_df, rp_spec_priority, adaptation_unit_costs, shortest_paths, graph_v, average_train_load_tons, average_train_cost_per_ton_km, average_road_cost_per_ton_km, demand_reduction_dict)\n",
    "\n",
    "    # Run adapted damages for full flood event\n",
    "    indirect_damages_adapted_full = calculate_indirect_dmgs_fullflood(full_flood_event, overlay_assets_lists, adaptation_run_full, assets, all_disrupted_edges, shortest_paths, graph_v, average_train_load_tons, average_train_cost_per_ton_km, average_road_cost_per_ton_km, demand_reduction_dict)\n",
    "\n",
    "    # Fill in missing values in dictionaries\n",
    "    for hazard_map in collect_output.keys():\n",
    "        if direct_damages_adapted[hazard_map]=={}:\n",
    "            direct_damages_adapted[hazard_map]=collect_output[hazard_map]\n",
    "        if indirect_damages_adapted[hazard_map]=={}:\n",
    "            indirect_damages_adapted[hazard_map]=event_impacts[hazard_map] if hazard_map in event_impacts.keys() else 0.0\n",
    "    \n",
    "    # Store results in dictionaries\n",
    "    direct_damages_adapted_dict[adapt_id] = direct_damages_adapted\n",
    "    indirect_damages_adapted_dict[adapt_id] = indirect_damages_adapted\n",
    "    indirect_damages_adapted_full_dict[adapt_id] = indirect_damages_adapted_full\n",
    "    adapted_assets_dict[adapt_id] = adapted_assets\n",
    "    adaptation_costs[adapt_id] = {'l1': l1_adaptation_costs, \n",
    "                                  'l2': l2_adaptation_costs, \n",
    "                                  'l3': l3_adaptation_costs}\n",
    "    adaptations_df.to_csv(data_path / 'interim' / 'adaptations' / f'{adapt_id}_adaptations.csv')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save raw output to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>l1_trib</th>\n",
       "      <th>l2_trib</th>\n",
       "      <th>l3_trib</th>\n",
       "      <th>l4_trib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': {}, 'flood...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': {}, 'flood...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': {}, 'flood...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': {}, 'flood...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': {}, 'flood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': 0.0, 'floo...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': 0.0, 'floo...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': 0.0, 'floo...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': 0, 'flood_...</td>\n",
       "      <td>{'flood_DERP_RW_H_4326_2080428500': 0, 'flood_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'flood_DERP_RW_H': 5929015.800494674, 'flood_...</td>\n",
       "      <td>{'flood_DERP_RW_H': 5918264.328845593, 'flood_...</td>\n",
       "      <td>{'flood_DERP_RW_H': 5427421.889182759, 'flood_...</td>\n",
       "      <td>{'flood_DERP_RW_H': 5929015.800494674, 'flood_...</td>\n",
       "      <td>{'flood_DERP_RW_H': 5427421.889182759, 'flood_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...</td>\n",
       "      <td>osm_id asset         name gauge   elec...</td>\n",
       "      <td>osm_id asset                name gauge...</td>\n",
       "      <td>Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...</td>\n",
       "      <td>Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'l1': None, 'l2': {}, 'l3': {}}</td>\n",
       "      <td>{'l1': {0: 266240624.64660648}, 'l2': {}, 'l3'...</td>\n",
       "      <td>{'l1': {}, 'l2': {'flood_DERP_RW_H_4326_208043...</td>\n",
       "      <td>{'l1': None, 'l2': {}, 'l3': {(219651487, 1119...</td>\n",
       "      <td>{'l1': None, 'l2': {}, 'l3': {}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            baseline  \\\n",
       "0  {'flood_DERP_RW_H_4326_2080428500': {}, 'flood...   \n",
       "1  {'flood_DERP_RW_H_4326_2080428500': 0.0, 'floo...   \n",
       "2  {'flood_DERP_RW_H': 5929015.800494674, 'flood_...   \n",
       "3  Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...   \n",
       "4                   {'l1': None, 'l2': {}, 'l3': {}}   \n",
       "\n",
       "                                             l1_trib  \\\n",
       "0  {'flood_DERP_RW_H_4326_2080428500': {}, 'flood...   \n",
       "1  {'flood_DERP_RW_H_4326_2080428500': 0.0, 'floo...   \n",
       "2  {'flood_DERP_RW_H': 5918264.328845593, 'flood_...   \n",
       "3          osm_id asset         name gauge   elec...   \n",
       "4  {'l1': {0: 266240624.64660648}, 'l2': {}, 'l3'...   \n",
       "\n",
       "                                             l2_trib  \\\n",
       "0  {'flood_DERP_RW_H_4326_2080428500': {}, 'flood...   \n",
       "1  {'flood_DERP_RW_H_4326_2080428500': 0.0, 'floo...   \n",
       "2  {'flood_DERP_RW_H': 5427421.889182759, 'flood_...   \n",
       "3          osm_id asset                name gauge...   \n",
       "4  {'l1': {}, 'l2': {'flood_DERP_RW_H_4326_208043...   \n",
       "\n",
       "                                             l3_trib  \\\n",
       "0  {'flood_DERP_RW_H_4326_2080428500': {}, 'flood...   \n",
       "1  {'flood_DERP_RW_H_4326_2080428500': 0, 'flood_...   \n",
       "2  {'flood_DERP_RW_H': 5929015.800494674, 'flood_...   \n",
       "3  Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...   \n",
       "4  {'l1': None, 'l2': {}, 'l3': {(219651487, 1119...   \n",
       "\n",
       "                                             l4_trib  \n",
       "0  {'flood_DERP_RW_H_4326_2080428500': {}, 'flood...  \n",
       "1  {'flood_DERP_RW_H_4326_2080428500': 0, 'flood_...  \n",
       "2  {'flood_DERP_RW_H': 5427421.889182759, 'flood_...  \n",
       "3  Empty GeoDataFrame\n",
       "Columns: [osm_id, asset, na...  \n",
       "4                   {'l1': None, 'l2': {}, 'l3': {}}  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report output dataframe\n",
    "output_df = pd.DataFrame.from_dict([direct_damages_adapted_dict, indirect_damages_adapted_dict, indirect_damages_adapted_full_dict, adapted_assets_dict, adaptation_costs])\n",
    "output_df.to_csv(data_path / 'output' / 'adaptations' / 'adaptations_output.csv')\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for adaptation: baseline\n",
      "Saved results for adaptation: l1_trib\n",
      "Saved results for adaptation: l2_trib\n",
      "Saved results for adaptation: l3_trib\n",
      "Saved results for adaptation: l4_trib\n"
     ]
    }
   ],
   "source": [
    "for adapt_id in adaptations.keys():\n",
    "    if not adapt_id in direct_damages_adapted_dict.keys():\n",
    "        continue\n",
    "    direct_damages_adapted_path = data_path / 'interim' / f'adapted_direct_damages_{adapt_id}.pkl'\n",
    "    indirect_damages_adapted_path = data_path / 'interim' / f'adapted_indirect_damages_{adapt_id}.pkl'\n",
    "    indirect_damages_adapted_full_path = data_path / 'interim' / f'adapted_indirect_damages_full_{adapt_id}.pkl'\n",
    "    # adaptations_df_path = data_path / 'output' / f'adaptations_{adapt_id}.csv'\n",
    "    adapted_assets_path = data_path / 'interim' / f'adapted_assets_{adapt_id}.pkl'\n",
    "    adaptation_costs_path = data_path / 'interim' / f'adaptation_costs_{adapt_id}.pkl'\n",
    "    adaptations_csv_path = data_path / 'interim' / 'adaptations' / f'{adapt_id}_adaptations.csv'\n",
    "\n",
    "\n",
    "    adaptations_df = pd.DataFrame.from_dict(adaptations[adapt_id])\n",
    "    \n",
    "\n",
    "    with open(direct_damages_adapted_path, 'wb') as f:\n",
    "        pickle.dump(direct_damages_adapted_dict[adapt_id], f)\n",
    "    with open(indirect_damages_adapted_path, 'wb') as f:\n",
    "        pickle.dump(indirect_damages_adapted_dict[adapt_id], f)\n",
    "    with open(indirect_damages_adapted_full_path, 'wb') as f:\n",
    "        pickle.dump(indirect_damages_adapted_full_dict[adapt_id], f)    \n",
    "    with open(adapted_assets_path, 'wb') as f:\n",
    "        pickle.dump(adapted_assets_dict[adapt_id], f)\n",
    "    with open(adaptation_costs_path, 'wb') as f:\n",
    "        pickle.dump(adaptation_costs[adapt_id], f)\n",
    "    print(f'Saved results for adaptation: {adapt_id}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci_adapt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
